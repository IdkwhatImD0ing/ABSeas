{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import aiohttp\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from anthropic import AsyncAnthropic\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "from transparent_background import Remover\n",
    "from elevenlabs.client import AsyncElevenLabs\n",
    "from elevenlabs import Voice, VoiceSettings\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are given lyrics from a song that I created.\n",
    "You are in charge of making a list of pictures relating to the song\n",
    "The pictures should be relevant to the text and be of individual items only.\n",
    "Each description should start with: a simple kid friendly cartoon illustration of...\n",
    "End with: on a white background\n",
    "Please give me 6 descriptions.\n",
    "\n",
    "Return a valid json list of objects:\n",
    "description: description of the item\n",
    "word: One word description\n",
    "learning: connection between the item and the song that can be understood by a three year old\n",
    "Example output\n",
    "[\n",
    "    {\n",
    "      description: \"a simple kid friendly cartoon illustration of a pirate hat on a white background\",\n",
    "      word: \"hat\",\n",
    "      learning: \"Pirates wear hats.\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "async def generate_metadata(lyrics):\n",
    "    client = AsyncAnthropic(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    "    )\n",
    "    openai_client = AsyncOpenAI()\n",
    "    remover = Remover()\n",
    "    eleven_client = AsyncElevenLabs(\n",
    "        api_key=os.environ.get(\"ELEVENLABS_API_KEY\"),\n",
    "    )\n",
    "    semaphore = asyncio.Semaphore(5)\n",
    "    async def generate_text(text, script):\n",
    "        message = await client.messages.create(\n",
    "            temperature=0.5,\n",
    "            max_tokens=1024,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": text + script,\n",
    "                },\n",
    "                {\"role\": \"assistant\", \"content\": \"[\"},\n",
    "            ],\n",
    "            model=\"claude-3-opus-20240229\",\n",
    "        )\n",
    "\n",
    "        return message.content\n",
    "    \n",
    "    async def fetch_image_binary(url):\n",
    "        async with aiohttp.ClientSession() as session:\n",
    "            async with session.get(url) as response:\n",
    "                # Make sure the request was successful\n",
    "                if response.status == 200:\n",
    "                    # Read and return the binary content of the image\n",
    "                    return await response.read()\n",
    "                else:\n",
    "                    # Handle possible HTTP errors (e.g., 404 Not Found) here if needed\n",
    "                    return None\n",
    "\n",
    "\n",
    "    async def generate_image(description):\n",
    "        response = await openai_client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=description,\n",
    "            size=\"1024x1024\",\n",
    "            quality=\"standard\",\n",
    "            n=1,\n",
    "        )\n",
    "        image_binary = await fetch_image_binary(response.data[0].url)\n",
    "        return image_binary\n",
    "\n",
    "\n",
    "    async def generate_images(pictures):\n",
    "        tasks = [generate_image(picture['description']) for picture in pictures]\n",
    "        imgs = await asyncio.gather(*tasks)\n",
    "        return imgs\n",
    "    \n",
    "    async def text_to_speech(text, index):\n",
    "        # Acquire a semaphore\n",
    "        async with semaphore:\n",
    "            audio = await eleven_client.generate(\n",
    "                text=text,\n",
    "                voice=Voice(\n",
    "                    voice_id='Djuu0cAOk0e1MdFhrmnj',\n",
    "                    settings=VoiceSettings(stability=0.3, similarity_boost=0.75, style=0.0, use_speaker_boost=True)\n",
    "                ),\n",
    "                model=\"eleven_multilingual_v2\"\n",
    "            )\n",
    "            \n",
    "            out = b''\n",
    "            async for value in audio:\n",
    "                out += value\n",
    "                \n",
    "        # The semaphore is automatically released when the block is exited\n",
    "        return out\n",
    "\n",
    "    async def generate_audios(pictures):\n",
    "        tasks = [text_to_speech(picture['learning'], i) for i, picture in enumerate(pictures)]\n",
    "        audios = await asyncio.gather(*tasks)\n",
    "        return audios\n",
    "\n",
    "\n",
    "    pictures = await generate_text(lyrics, prompt)\n",
    "    pictures = json.loads(\"[\"+pictures[0].text)\n",
    "    imgs = await generate_images(pictures)\n",
    "    removed = [remover.process(Image.open(BytesIO(img))) for img in imgs]\n",
    "    b64_imgs = []\n",
    "    for img in removed:\n",
    "        buffered = BytesIO()\n",
    "        # Convert rgba \n",
    "        img = img.convert(\"RGB\")\n",
    "        img.save(buffered, format=\"JPEG\")\n",
    "        img_str = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "        b64_imgs.append(img_str)\n",
    "    \n",
    "    # audios is a list of bytes\n",
    "    # Let's convert them to b64 strings\n",
    "    \n",
    "    audios = await generate_audios(pictures)\n",
    "    b64_audios = [base64.b64encode(audio).decode(\"utf-8\") for audio in audios]\n",
    "    \n",
    "    return {\n",
    "        \"pictures\": b64_imgs,\n",
    "        \"audios\": b64_audios\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings -> Mode=base, Device=mps:0, Torchscript=disabled\n"
     ]
    }
   ],
   "source": [
    "lyrics=\"\"\"\n",
    "Verse 1:\n",
    "When yer sailin' on the seas (yo-ho!)\n",
    "And you've got some tasty treats (arr!)\n",
    "Don't forget to share with mates\n",
    "That's what every pirate states! (ahoy!)\n",
    "\n",
    "Chorus:\n",
    "Sharin' is carin', me hearties know\n",
    "It fills our hearts with a friendly glow\n",
    "Whether it's treasure or a yummy snack\n",
    "Sharin' with others keeps the smiles on track! (yo-ho!)\n",
    "\n",
    "Verse 2:\n",
    "If you've got a shiny coin (avast!)\n",
    "Or a scrumptious candy growin'\n",
    "Pass it 'round to all yer crew\n",
    "Sharin' makes the skies more blue! (arr!)\n",
    "\n",
    "Chorus:\n",
    "Sharin' is carin', me hearties know\n",
    "It fills our hearts with a friendly glow\n",
    "\n",
    "Whether it's treasure or a yummy snack\n",
    "Sharin' with others keeps the smiles on track! (yo-ho!)\n",
    "\"\"\"\n",
    "\n",
    "results = asyncio.run(generate_metadata(lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert one to mp3 and save\n",
    "audio = results['audios'][0]\n",
    "with open( \"audio.mp3\", \"wb\") as f:\n",
    "    f.write(base64.b64decode(audio))\n",
    "    \n",
    "# Convert one image to png and save\n",
    "img = results['pictures'][0]\n",
    "img = base64.b64decode(img)\n",
    "img = Image.open(BytesIO(img))\n",
    "img.save(\"image.png\", \"PNG\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "abseas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
